import { match } from "ts-pattern";
import { TOKEN, TOKEN_STRUCT, keywords } from "./token";

export type LexerMeta = {
  ì…ë ¥_ê°’: string;
  í˜„_ìœ„ì¹˜: number;
  ë‹¤ìŒ_ì½ì„_ìœ„ì¹˜: number;
  í˜„ì¬_ë¬¸ì: string;
};

export const ì¢…ë£Œ = "ğŸ˜‡";

export const createLexer = (code: string) => {};
export const nextToken = (
  ë©”íƒ€ì •ë³´: LexerMeta
): {
  token: {
    type: (typeof TOKEN)[keyof typeof TOKEN];
    literal: string;
  };
  meta: LexerMeta;
} => {
  const ê³µë°±ì œê±°_ë©”íƒ€ì •ë³´ = skipWhitespace(ë©”íƒ€ì •ë³´);

  const { ë©”íƒ€ì •ë³´: ìƒˆ_ë©”íƒ€ì •ë³´, ...token } = classifyToken(ê³µë°±ì œê±°_ë©”íƒ€ì •ë³´);
  return {
    token: token,
    meta: ìƒˆ_ë©”íƒ€ì •ë³´,
  };
};

export const readChar = (ë©”íƒ€ì •ë³´: LexerMeta): LexerMeta => {
  const { ë‹¤ìŒ_ì½ì„_ìœ„ì¹˜, ì…ë ¥_ê°’ } = ë©”íƒ€ì •ë³´;
  if (ë‹¤ìŒ_ì½ì„_ìœ„ì¹˜ >= ì…ë ¥_ê°’.length) {
    return {
      ...ë©”íƒ€ì •ë³´,
      í˜„_ìœ„ì¹˜: ë‹¤ìŒ_ì½ì„_ìœ„ì¹˜,
      ë‹¤ìŒ_ì½ì„_ìœ„ì¹˜: ë‹¤ìŒ_ì½ì„_ìœ„ì¹˜ + 1,
      í˜„ì¬_ë¬¸ì: ì¢…ë£Œ,
    };
  }

  return {
    ...ë©”íƒ€ì •ë³´,
    í˜„_ìœ„ì¹˜: ë‹¤ìŒ_ì½ì„_ìœ„ì¹˜,
    ë‹¤ìŒ_ì½ì„_ìœ„ì¹˜: ë‹¤ìŒ_ì½ì„_ìœ„ì¹˜ + 1,
    í˜„ì¬_ë¬¸ì: ì…ë ¥_ê°’[ë‹¤ìŒ_ì½ì„_ìœ„ì¹˜],
  };
};

export const skipWhitespace = (ë©”íƒ€ì •ë³´: LexerMeta) => {
  let _ë©”íƒ€ì •ë³´ = ë©”íƒ€ì •ë³´;
  while ([" ", "\t", "\n", "\r"].includes(_ë©”íƒ€ì •ë³´.í˜„ì¬_ë¬¸ì)) {
    _ë©”íƒ€ì •ë³´ = readChar(_ë©”íƒ€ì •ë³´);
  }
  return _ë©”íƒ€ì •ë³´;
};

export const classifyToken = (ë©”íƒ€ì •ë³´: LexerMeta) => {
  const token = match(ë©”íƒ€ì •ë³´.í˜„ì¬_ë¬¸ì)
    .with(ì¢…ë£Œ, () => {
      const _ë©”íƒ€ì •ë³´ = readChar(ë©”íƒ€ì •ë³´);
      return { literal: "", type: TOKEN.EOF, ë©”íƒ€ì •ë³´: _ë©”íƒ€ì •ë³´ };
    })
    .with(";", () => {
      const _ë©”íƒ€ì •ë³´ = readChar(ë©”íƒ€ì •ë³´);
      return { literal: ";", type: TOKEN.SEMICOLON, ë©”íƒ€ì •ë³´: _ë©”íƒ€ì •ë³´ };
    })
    .with("=", () => {
      const _ë©”íƒ€ì •ë³´ = readChar(ë©”íƒ€ì •ë³´);
      return { literal: "=", type: TOKEN.ASSIGN, ë©”íƒ€ì •ë³´: _ë©”íƒ€ì •ë³´ };
    })
    .otherwise(() => {
      if (isLetter(ë©”íƒ€ì •ë³´.í˜„ì¬_ë¬¸ì)) {
        const { literal, ë©”íƒ€ì •ë³´: _ë©”íƒ€ì •ë³´ } = readIdentifier(ë©”íƒ€ì •ë³´);
        const type = lookupIdent(literal);
        return { literal, type, ë©”íƒ€ì •ë³´: _ë©”íƒ€ì •ë³´ };
      } else if (isDigit(ë©”íƒ€ì •ë³´.í˜„ì¬_ë¬¸ì)) {
        const { literal, ë©”íƒ€ì •ë³´: _ë©”íƒ€ì •ë³´ } = readNumber(ë©”íƒ€ì •ë³´);
        return {
          ë©”íƒ€ì •ë³´: _ë©”íƒ€ì •ë³´,
          type: TOKEN.INT,
          literal: literal,
        };
      }
    });

  return token;
};

const readIdentifier = (ë©”íƒ€ì •ë³´: LexerMeta) => {
  let _ë©”íƒ€ì •ë³´ = ë©”íƒ€ì •ë³´;
  while (isLetter(_ë©”íƒ€ì •ë³´.í˜„ì¬_ë¬¸ì)) {
    _ë©”íƒ€ì •ë³´ = readChar(_ë©”íƒ€ì •ë³´);
  }
  return {
    ë©”íƒ€ì •ë³´: _ë©”íƒ€ì •ë³´,
    literal: _ë©”íƒ€ì •ë³´.ì…ë ¥_ê°’.substring(ë©”íƒ€ì •ë³´.í˜„_ìœ„ì¹˜, _ë©”íƒ€ì •ë³´.í˜„_ìœ„ì¹˜),
  };
};

const readNumber = (ë©”íƒ€ì •ë³´: LexerMeta) => {
  let _ë©”íƒ€ì •ë³´ = ë©”íƒ€ì •ë³´;
  while (isDigit(_ë©”íƒ€ì •ë³´.í˜„ì¬_ë¬¸ì)) {
    _ë©”íƒ€ì •ë³´ = readChar(_ë©”íƒ€ì •ë³´);
  }
  return {
    ë©”íƒ€ì •ë³´: _ë©”íƒ€ì •ë³´,
    literal: _ë©”íƒ€ì •ë³´.ì…ë ¥_ê°’.substring(ë©”íƒ€ì •ë³´.í˜„_ìœ„ì¹˜, _ë©”íƒ€ì •ë³´.í˜„_ìœ„ì¹˜),
  };
};

const lookupIdent = (ident: string) => {
  if (keywords[ident]) {
    return keywords[ident];
  }
  return TOKEN.IDENT;
};

const isLetter = (ch: string): boolean => {
  return ("a" <= ch && ch <= "z") || ("A" <= ch && ch <= "Z") || ch == "_";
};

const isDigit = (ch: string): boolean => {
  return "0" <= ch && ch <= "9";
};
